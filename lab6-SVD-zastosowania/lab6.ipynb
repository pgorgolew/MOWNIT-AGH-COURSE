{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Metody Obliczeniowe w Nauce i Technice Laboratorium 6\n",
    "## Page searcher\n",
    "### Paweł Gorgolewski"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import csv\n",
    "import wikipedia as wiki\n",
    "from typing import List, Dict, DefaultDict\n",
    "from wikipedia.exceptions import WikipediaException\n",
    "from collections import namedtuple, defaultdict\n",
    "from functools import reduce\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "from time import time\n",
    "from concurrent.futures import ProcessPoolExecutor\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Generating wiki dump\n",
    "Dump indeksów artykułów z wikipedii został pobrany poprzez link\n",
    "https://dumps.wikimedia.org/enwiki/20220401/\n",
    "\n",
    "Mając tytuły wszystkich artykuł, zaciągamy zawartość tytułu poprzez bilbiotekę *wikipedia*. Następnie zapisujemy pickle pythonowe w celu łatwego ładowania do programu"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def get_first_n_titles(n=1500, file='data\\wiki-pages-indexes.txt'):\n",
    "    titles = []\n",
    "    with open(file, \"r\", encoding='utf8') as f:\n",
    "        csv_reader = csv.reader(f, delimiter=\":\")\n",
    "        for row in csv_reader:\n",
    "            if n < 0:\n",
    "                break\n",
    "\n",
    "            title = row[-1]\n",
    "            if '/' in title:\n",
    "                continue\n",
    "\n",
    "            titles.append(title)\n",
    "            n-=1\n",
    "\n",
    "    return titles\n",
    "\n",
    "def get_articles_content_and_save_pickle(titles: List[str]):\n",
    "    not_matched = 0\n",
    "    for title in titles:\n",
    "        try:\n",
    "            wiki_page = wiki.page(title)\n",
    "            wiki_content = wiki_page.content\n",
    "            #now saving pickle\n",
    "            pickle.dump(wiki_content, open(f'data\\\\{title}', \"wb\"))\n",
    "        except WikipediaException:\n",
    "            not_matched += 1\n",
    "\n",
    "    print(f\"Not matched {not_matched} titles\")\n",
    "\n",
    "#titles = get_first_n_titles()\n",
    "#get_articles_content_and_save_pickle(titles)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ładowanie artykułów"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def get_articles(to_omit_file='wiki-pages-indexes.txt'):\n",
    "    data_by_title = dict()\n",
    "    for title in pickles():\n",
    "        if title == to_omit_file or \"dump\" in title:\n",
    "            continue\n",
    "\n",
    "        data_by_title[title] = pickle.load(open(f\"data\\\\{title}\", \"rb\"))\n",
    "\n",
    "    pickle.dump(data_by_title, open(f\"data\\\\dumps\\\\articles_dict_dump_of_len_{len(data_by_title)}\", \"wb\"))\n",
    "    return data_by_title\n",
    "\n",
    "def pickles(path='data'):\n",
    "    for content in os.listdir(path):\n",
    "        if os.path.isfile(os.path.join(path, content)):\n",
    "            yield content\n",
    "\n",
    "def get_articles_from_dump(dirpath=\"data\\\\dumps\\\\\", dump_name=\"articles_dict_dump_of_len_1255\"):\n",
    "    path = os.path.join(dirpath, dump_name)\n",
    "    return pickle.load(open(path, \"rb\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Używam wcześniej zapisanych struktur, aby nie tracić czasu na tworzenie ich."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "#articles = get_articles()\n",
    "articles = get_articles_from_dump()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tworzenie zbioru wszystkich słów"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4898002\n",
      "5540\n"
     ]
    }
   ],
   "source": [
    "ArticleData = namedtuple('ArticleData', ['words_data', 'words_count', 'unique_words_count'])\n",
    "class ArticlesParser:\n",
    "    def __init__(self, articles: Dict[str, str]):\n",
    "        self.articles = articles\n",
    "        self.parsed_articles = dict()\n",
    "        self.all_words_count = 0\n",
    "        self.all_words_data = defaultdict(lambda: 0)\n",
    "\n",
    "    def parse_article(self, content: str):\n",
    "        all_words = content.split()\n",
    "        words_data = defaultdict(lambda: 0)\n",
    "\n",
    "        for word in all_words:\n",
    "            words_data[word] += 1\n",
    "            self.all_words_data[word] += 1\n",
    "\n",
    "        self.all_words_count += len(all_words)\n",
    "        return ArticleData(words_data=words_data, words_count=len(all_words), unique_words_count=len(words_data))\n",
    "\n",
    "    def parse_articles(self):\n",
    "        for article in articles:\n",
    "            self.parsed_articles[article] = self.parse_article(articles[article])\n",
    "\n",
    "\n",
    "parser = ArticlesParser(articles)\n",
    "parser.parse_articles()\n",
    "print(parser.all_words_count)\n",
    "print(parser.all_words_data['A'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}